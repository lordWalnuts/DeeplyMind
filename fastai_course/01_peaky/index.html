<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Classifying Peaky Blinders Characters using fast.ai | DeeplyMind</title><meta name=keywords content="fast.ai,image classification,fast.ai course"><meta name=description content="Using fast.ai and resnet50 to classify images"><meta name=author content="Koushik Balakrishnan"><link rel=canonical href=https://lordwalnuts.github.io/deeplymind/fastai_course/01_peaky/><link crossorigin=anonymous href=/deeplymind/assets/css/stylesheet.b183800e2cfbb62c3bce2b2ba56cdb2dd33af76c75cf4550173d5dfebd7c68a6.css integrity="sha256-sYOADiz7tiw7zisrpWzbLdM692x1z0VQFz1d/r18aKY=" rel="preload stylesheet" as=style><link rel=icon href=https://lordwalnuts.github.io/deeplymind/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://lordwalnuts.github.io/deeplymind/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://lordwalnuts.github.io/deeplymind/favicon-32x32.png><link rel=apple-touch-icon href=https://lordwalnuts.github.io/deeplymind/apple-touch-icon.png><link rel=mask-icon href=https://lordwalnuts.github.io/deeplymind/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Classifying Peaky Blinders Characters using fast.ai"><meta property="og:description" content="Using fast.ai and resnet50 to classify images"><meta property="og:type" content="article"><meta property="og:url" content="https://lordwalnuts.github.io/deeplymind/fastai_course/01_peaky/"><meta property="article:section" content="fastai_course"><meta property="article:published_time" content="2022-12-02T00:00:00+00:00"><meta property="article:modified_time" content="2022-12-02T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Classifying Peaky Blinders Characters using fast.ai"><meta name=twitter:description content="Using fast.ai and resnet50 to classify images"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Fastai_courses","item":"https://lordwalnuts.github.io/deeplymind/fastai_course/"},{"@type":"ListItem","position":2,"name":"Classifying Peaky Blinders Characters using fast.ai","item":"https://lordwalnuts.github.io/deeplymind/fastai_course/01_peaky/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Classifying Peaky Blinders Characters using fast.ai","name":"Classifying Peaky Blinders Characters using fast.ai","description":"Using fast.ai and resnet50 to classify images","keywords":["fast.ai","image classification","fast.ai course"],"articleBody":"Intro We’ll try to build an image classification model that identifies each member of the Peaky Blinders family.\nThis is based on Lesson 1 of the “Practical Deep Learning for Coders 2022” course by fast.ai\n(Also part of my Fast.ai Course series where I document my journey going through the Fast.ai course)\nI view the process of training this model as three pieces:\nCollecting the Data Loading the Dataset into Dataloaders Training the model Before diving in, we need to set up the machine by installing necessary libraries\nThe completed Google Colab notebook is linked in the Resources section\nSetting up Google Colab I use Google Colab because I find it intuitive and can connect it with Google Drive to save the notebooks and data.\nYou can find detailed information on how to set up Jupyter notebooks on different platforms here\nOpen a new Notebook and in the first code block, enter the following code\n!pip install -Uqq fastai !pip install duckduckgo_search We prefix ! When using bash commands. It’s mostly used to install libraries and copy/move files around in our use case We install fastai and duckduckgo_search libraries where the latter is used to download images as we shall see in the next section Hint: Don’t forget to change the runtime of your notebook to GPU. You do that by Runtime \u003e change runtime type \u003e GPU\nCollecting the Data Downloading Data First import the following modules from duckduckgo_search import ddg_images from fastcore.all import * from fastdownload import download_url from fastai.vision.all import * Then we define the search_images function def search_images(term, max_images=30): print(f\"Searching for '{term}'\") return L(ddg_images(term,max_results=max_images)).itemgot('image') L is just a fast.ai component which returns a List\nNext we define our search terms and download the images. I use two Lists, the first list downloads the images the actors in Peaky Blinders set and the other downloads general images of actors This would be ideal since we would get images from different perspective and time period. This would force the model to learn from unique facial features search_terms_1 = ['Thomas Shelby','Arthur Shelby','Ada Shelby','Polly Gray','Michael Gray','John Shelby'] search_terms_2 = ['Cillian Murphy','Paul Anderson','Sophie Rundle','Helen McCrory','Joe Cole','Finn Cole'] path = Path('peaky_blinders_family') from time import sleep for index in range(0,len(search_terms_1)): dest = (path/search_terms_1[index]) dest.mkdir(exist_ok=True,parents=True) download_images(dest,urls=search_images(f'{search_terms_1[index]} peaky blinders photo',max_images=30)) sleep(10) download_images(dest,urls=search_images(f'{search_terms_2[index]} actor photo',max_images=30)) resize_images(path/search_terms_1[index],max_size=400,dest=path/search_terms_1[index]) - sleep(10) is used to not overload the server - we resize the images to 400 since it's the most suited size for GPU training. Cleaning the Data There’s a high chance that some the photos are broken or corrupted. We can use verify_images function to easily check for them and remove them using unlink method path = Path('peaky_blinders_family') failed = verify_images(get_image_files(path)) failed.map(Path.unlink) len(failed) # to check number of failed items Now we have our Dataset downloaded and cleaned\nMoving the dataset to Google drive (Optional) If you plan on using this dataset again in the future, you should consider moving it to Google Drive. You could easily download it from there and also use it in other Colab Notebooks\nfrom google.colab import drive drive.mount('/content/drive') You will be prompted to sign in with your google account. Create a folder called dataset in your drive and use the following command to copy it to google drive\n!cp peaky_blinders_family/ drive/MyDrive/dataset/ Loading the Dataset into Dataloaders The following is from the Kaggle Notebook for lesson 1:\n“To train a model, we’ll need DataLoaders, which is an object that contains a training set (the images used to create a model) and a validation set (the images used to check the accuracy of a model – not used during training).”\nFirst we create a Datablock with various parameters and then pass it to Dataloaders object dls = DataBlock( blocks=(ImageBlock,CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2,seed=42), get_y=parent_label, item_tfms=[Resize(192,method='squish')] ) Here what each of the DataBlock parameters means:\nblocks=(ImageBlock, CategoryBlock), Represents the Input and output types. In this case our input is an image and output is category(Tommy or Arthur etc.)\nget_items=get_image_files, gets the image files\nsplitter=RandomSplitter(valid_pct=0.2, seed=42), Splits the dataset into Training and Validation set. Training set are used to train the model and Validation set is used to test the accuracy of the model. In this case 0.2% of the dataset are Validation set\nget_y=parent_label, Sets the output value. In this case we just use the folder name of the parent folder(Cillian Murphy etc.).\nitem_tfms=[Resize(192, method='squish')] Resizes the images by squishing it.\nWe then call Dataloaders on the Datablock dls dls=dls.dataloaders(path,bs=42) bs defines how many samples per batch to load.\nHint: If any of the parameters are confusing, you can always read about them in the fast.ai documentation. For example, here is the page for dataloaders class\nTraining the Model We can use one of the many pretrained models available to fine tune our model. For our task we shall use the resnet50 model.\nFine-Tuning saves a lot of time by initializing the downloaded model with the set of weights that works the best.\nlearn = vision_learner(dls,resnet50,metrics=error_rate) learn.fine_tune(5) I used 5 epochs as it gives me the least possible error rate through trial and error. I also tried other models such as resnet18 but the one we chose performs exponentially better with lower error rates.\nTesting our Model Let’s upload some pictures to the notebook and test our model.\nWe load a test image using PILImage.Create() and use predict method on with it\nim = Path('drive/MyDrive/peaky_test/art1.jpg') member,_,probs = learn.predict(PILImage.create(im)) print(f\"This is {member}\") print(f\"Probability it's {member}: {probs[0]:.4f}\") We get correct results for every test images with probability of 0.9 and above.\nConclusion It’s incredible how easy it is to train an image classification model in under 30mins and with little data. It would seem that massive amounts of data are required to train something like this, but we’ve done it with 60 Images.\nResources and Links fast.ai Course fast.ai book lesson 1 fast.ai forums for lesson 1 Colab Notebook for this lesson ","wordCount":"972","inLanguage":"en","datePublished":"2022-12-02T00:00:00Z","dateModified":"2022-12-02T00:00:00Z","author":{"@type":"Person","name":"Koushik Balakrishnan"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://lordwalnuts.github.io/deeplymind/fastai_course/01_peaky/"},"publisher":{"@type":"Organization","name":"DeeplyMind","logo":{"@type":"ImageObject","url":"https://lordwalnuts.github.io/deeplymind/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://lordwalnuts.github.io/deeplymind/ accesskey=h title="DeeplyMind (Alt + H)">DeeplyMind</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://lordwalnuts.github.io/deeplymind/archives title=Archive><span>Archive</span></a></li><li><a href=https://lordwalnuts.github.io/deeplymind/search/ title=Search><span>Search</span></a></li><li><a href=https://lordwalnuts.github.io/deeplymind/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Classifying Peaky Blinders Characters using fast.ai</h1><div class=post-meta><span title='2022-12-02 00:00:00 +0000 UTC'>December 2, 2022</span>&nbsp;·&nbsp;972 words&nbsp;·&nbsp;Koushik Balakrishnan</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#intro aria-label=Intro>Intro</a></li><li><a href=#setting-up-google-colab aria-label="Setting up Google Colab">Setting up Google Colab</a></li><li><a href=#collecting-the-data aria-label="Collecting the Data">Collecting the Data</a><ul><ul><li><a href=#downloading-data aria-label="Downloading Data">Downloading Data</a></li><li><a href=#cleaning-the-data aria-label="Cleaning the Data">Cleaning the Data</a></li><li><a href=#moving-the-dataset-to-google-drive-optional aria-label="Moving the dataset to Google drive (Optional)">Moving the dataset to Google drive (Optional)</a></li></ul></ul></li><li><a href=#loading-the-dataset-into-dataloaders aria-label="Loading the Dataset into Dataloaders">Loading the Dataset into <code>Dataloaders</code></a></li><li><a href=#training-the-model aria-label="Training the Model">Training the Model</a></li><li><a href=#testing-our-model aria-label="Testing our Model">Testing our Model</a></li><li><a href=#conclusion aria-label=Conclusion>Conclusion</a></li><li><a href=#resources-and-links aria-label="Resources and Links">Resources and Links</a></li></ul></div></details></div><div class=post-content><h1 id=intro>Intro<a hidden class=anchor aria-hidden=true href=#intro>#</a></h1><p>We&rsquo;ll try to build an image classification model that identifies each member of the Peaky Blinders family.</p><p>This is based on Lesson 1 of the <a href=https://course.fast.ai/>&ldquo;Practical Deep Learning for Coders 2022&rdquo;</a> course by <a href=https://www.fast.ai/>fast.ai</a></p><p>(Also part of my Fast.ai Course series where I document my journey going through the Fast.ai course)</p><p>I view the process of training this model as three pieces:</p><ol><li>Collecting the Data</li><li>Loading the Dataset into <code>Dataloaders</code></li><li>Training the model</li></ol><p>Before diving in, we need to set up the machine by installing necessary libraries</p><p>The completed Google Colab notebook is linked in the Resources section</p><h1 id=setting-up-google-colab>Setting up Google Colab<a hidden class=anchor aria-hidden=true href=#setting-up-google-colab>#</a></h1><p>I use Google Colab because I find it intuitive and can connect it with Google Drive to save the notebooks and data.</p><p>You can find detailed information on how to set up Jupyter notebooks on different platforms <a href=https://course.fast.ai/Lessons/lesson1.html>here</a></p><p>Open a new Notebook and in the first code block, enter the following code</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>!</span>pip install <span style=color:#f92672>-</span>Uqq fastai
</span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>!</span>pip install duckduckgo_search
</span></span></code></pre></div><ul><li>We prefix <strong>!</strong> When using bash commands. It&rsquo;s mostly used to install libraries and copy/move files around in our use case</li><li>We install <strong>fastai</strong> and <strong>duckduckgo_search</strong> libraries where the latter is used to download images as we shall see in the next section</li></ul><p><em>Hint</em>: Don&rsquo;t forget to change the runtime of your notebook to GPU. You do that by <em>Runtime > change runtime type > GPU</em></p><h1 id=collecting-the-data>Collecting the Data<a hidden class=anchor aria-hidden=true href=#collecting-the-data>#</a></h1><h3 id=downloading-data>Downloading Data<a hidden class=anchor aria-hidden=true href=#downloading-data>#</a></h3><ul><li>First import the following modules</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> duckduckgo_search <span style=color:#f92672>import</span> ddg_images
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> fastcore.all <span style=color:#f92672>import</span> <span style=color:#f92672>*</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> fastdownload <span style=color:#f92672>import</span> download_url
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> fastai.vision.all <span style=color:#f92672>import</span> <span style=color:#f92672>*</span>
</span></span></code></pre></div><ul><li>Then we define the <strong>search_images</strong> function</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>search_images</span>(term, max_images<span style=color:#f92672>=</span><span style=color:#ae81ff>30</span>):
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Searching for &#39;</span><span style=color:#e6db74>{</span>term<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;&#34;</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> L(ddg_images(term,max_results<span style=color:#f92672>=</span>max_images))<span style=color:#f92672>.</span>itemgot(<span style=color:#e6db74>&#39;image&#39;</span>)
</span></span></code></pre></div><p>L is just a fast.ai component which returns a List</p><ul><li>Next we define our search terms and download the images. I use two Lists, the first list downloads the images the actors in Peaky Blinders set and the other downloads general images of actors</li><li>This would be ideal since we would get images from different perspective and time period. This would force the model to learn from unique facial features</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>search_terms_1 <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;Thomas Shelby&#39;</span>,<span style=color:#e6db74>&#39;Arthur Shelby&#39;</span>,<span style=color:#e6db74>&#39;Ada Shelby&#39;</span>,<span style=color:#e6db74>&#39;Polly Gray&#39;</span>,<span style=color:#e6db74>&#39;Michael Gray&#39;</span>,<span style=color:#e6db74>&#39;John Shelby&#39;</span>]
</span></span><span style=display:flex><span>search_terms_2 <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;Cillian Murphy&#39;</span>,<span style=color:#e6db74>&#39;Paul Anderson&#39;</span>,<span style=color:#e6db74>&#39;Sophie Rundle&#39;</span>,<span style=color:#e6db74>&#39;Helen McCrory&#39;</span>,<span style=color:#e6db74>&#39;Joe Cole&#39;</span>,<span style=color:#e6db74>&#39;Finn Cole&#39;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>path <span style=color:#f92672>=</span> Path(<span style=color:#e6db74>&#39;peaky_blinders_family&#39;</span>)
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> time <span style=color:#f92672>import</span> sleep
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> index <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>0</span>,len(search_terms_1)):
</span></span><span style=display:flex><span>  dest <span style=color:#f92672>=</span> (path<span style=color:#f92672>/</span>search_terms_1[index])
</span></span><span style=display:flex><span>  dest<span style=color:#f92672>.</span>mkdir(exist_ok<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,parents<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>  download_images(dest,urls<span style=color:#f92672>=</span>search_images(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;</span><span style=color:#e6db74>{</span>search_terms_1[index]<span style=color:#e6db74>}</span><span style=color:#e6db74> peaky blinders photo&#39;</span>,max_images<span style=color:#f92672>=</span><span style=color:#ae81ff>30</span>))
</span></span><span style=display:flex><span>  sleep(<span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>  download_images(dest,urls<span style=color:#f92672>=</span>search_images(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;</span><span style=color:#e6db74>{</span>search_terms_2[index]<span style=color:#e6db74>}</span><span style=color:#e6db74> actor photo&#39;</span>,max_images<span style=color:#f92672>=</span><span style=color:#ae81ff>30</span>))
</span></span><span style=display:flex><span>  resize_images(path<span style=color:#f92672>/</span>search_terms_1[index],max_size<span style=color:#f92672>=</span><span style=color:#ae81ff>400</span>,dest<span style=color:#f92672>=</span>path<span style=color:#f92672>/</span>search_terms_1[index])
</span></span></code></pre></div><pre><code>- sleep(10) is used to not overload the server
- we resize the images to 400 since it's the most suited size for GPU training. 
</code></pre><h3 id=cleaning-the-data>Cleaning the Data<a hidden class=anchor aria-hidden=true href=#cleaning-the-data>#</a></h3><ul><li>There&rsquo;s a high chance that some the photos are broken or corrupted. We can use <strong>verify_images</strong> function to easily check for them and remove them using <strong>unlink</strong> method</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>path <span style=color:#f92672>=</span> Path(<span style=color:#e6db74>&#39;peaky_blinders_family&#39;</span>)
</span></span><span style=display:flex><span>failed <span style=color:#f92672>=</span> verify_images(get_image_files(path))
</span></span><span style=display:flex><span>failed<span style=color:#f92672>.</span>map(Path<span style=color:#f92672>.</span>unlink)
</span></span><span style=display:flex><span>len(failed) <span style=color:#75715e># to check number of failed items</span>
</span></span></code></pre></div><p>Now we have our Dataset downloaded and cleaned</p><h3 id=moving-the-dataset-to-google-drive-optional>Moving the dataset to Google drive (Optional)<a hidden class=anchor aria-hidden=true href=#moving-the-dataset-to-google-drive-optional>#</a></h3><p>If you plan on using this dataset again in the future, you should consider moving it to Google Drive. You could easily download it from there and also use it in other Colab Notebooks</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> google.colab <span style=color:#f92672>import</span> drive
</span></span><span style=display:flex><span>drive<span style=color:#f92672>.</span>mount(<span style=color:#e6db74>&#39;/content/drive&#39;</span>)
</span></span></code></pre></div><pre><code>You will be prompted to sign in with your google account.
</code></pre><p>Create a folder called dataset in your drive and use the following command to copy it to google drive</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>!</span>cp peaky_blinders_family<span style=color:#f92672>/</span> drive<span style=color:#f92672>/</span>MyDrive<span style=color:#f92672>/</span>dataset<span style=color:#f92672>/</span>
</span></span></code></pre></div><h1 id=loading-the-dataset-into-dataloaders>Loading the Dataset into <code>Dataloaders</code><a hidden class=anchor aria-hidden=true href=#loading-the-dataset-into-dataloaders>#</a></h1><p>The following is from the <a href=https://www.kaggle.com/code/jhoward/is-it-a-bird-creating-a-model-from-your-own-data>Kaggle Notebook</a> for lesson 1:</p><p><em>&ldquo;To train a model, we&rsquo;ll need DataLoaders, which is an object that contains a training set (the images used to create a model) and a validation set (the images used to check the accuracy of a model &ndash; not used during training).&rdquo;</em></p><ul><li>First we create a <code>Datablock</code> with various parameters and then pass it to <code>Dataloaders</code> object</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>dls <span style=color:#f92672>=</span> DataBlock(
</span></span><span style=display:flex><span>    blocks<span style=color:#f92672>=</span>(ImageBlock,CategoryBlock),
</span></span><span style=display:flex><span>    get_items<span style=color:#f92672>=</span>get_image_files,
</span></span><span style=display:flex><span>    splitter<span style=color:#f92672>=</span>RandomSplitter(valid_pct<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>,seed<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>),
</span></span><span style=display:flex><span>    get_y<span style=color:#f92672>=</span>parent_label,
</span></span><span style=display:flex><span>    item_tfms<span style=color:#f92672>=</span>[Resize(<span style=color:#ae81ff>192</span>,method<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;squish&#39;</span>)]
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><p>Here what each of the <code>DataBlock</code> parameters means:</p><pre><code>blocks=(ImageBlock, CategoryBlock),
</code></pre><p>Represents the Input and output types. In this case our input is an image and output is category(Tommy or Arthur etc.)</p><pre><code>get_items=get_image_files, 
</code></pre><p>gets the image files</p><pre><code>splitter=RandomSplitter(valid_pct=0.2, seed=42),
</code></pre><p>Splits the dataset into Training and Validation set. Training set are used to train the model and Validation set is used to test the accuracy of the model. In this case 0.2% of the dataset are Validation set</p><pre><code>get_y=parent_label,
</code></pre><p>Sets the output value. In this case we just use the folder name of the parent folder(Cillian Murphy etc.).</p><pre><code>item_tfms=[Resize(192, method='squish')]
</code></pre><p>Resizes the images by squishing it.</p><ul><li>We then call <code>Dataloaders</code> on the <code>Datablock</code> dls</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>dls<span style=color:#f92672>=</span>dls<span style=color:#f92672>.</span>dataloaders(path,bs<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>)
</span></span></code></pre></div><p><code>bs</code> defines how many samples per batch to load.</p><p><em>Hint</em>: If any of the parameters are confusing, you can always read about them in the <a href=docs.fast.ai>fast.ai documentation</a>. For example, <a href=https://docs.fast.ai/data.load.html>here</a> is the page for <code>dataloaders</code> class</p><h1 id=training-the-model>Training the Model<a hidden class=anchor aria-hidden=true href=#training-the-model>#</a></h1><p>We can use one of the many pretrained models available to fine tune our model. For our task we shall use the <a href=https://pytorch.org/vision/main/models/generated/torchvision.models.resnet50.html><code>resnet50</code></a> model.</p><p>Fine-Tuning saves a lot of time by initializing the downloaded model with the set of weights that works the best.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>learn <span style=color:#f92672>=</span> vision_learner(dls,resnet50,metrics<span style=color:#f92672>=</span>error_rate)
</span></span><span style=display:flex><span>learn<span style=color:#f92672>.</span>fine_tune(<span style=color:#ae81ff>5</span>)
</span></span></code></pre></div><p>I used 5 epochs as it gives me the least possible error rate through trial and error. I also tried other models such as <code>resnet18</code> but the one we chose performs exponentially better with lower error rates.</p><h1 id=testing-our-model>Testing our Model<a hidden class=anchor aria-hidden=true href=#testing-our-model>#</a></h1><p>Let&rsquo;s upload some pictures to the notebook and test our model.</p><p>We load a test image using <code>PILImage.Create()</code> and use predict method on with it</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>im <span style=color:#f92672>=</span> Path(<span style=color:#e6db74>&#39;drive/MyDrive/peaky_test/art1.jpg&#39;</span>)
</span></span><span style=display:flex><span>member,_,probs <span style=color:#f92672>=</span> learn<span style=color:#f92672>.</span>predict(PILImage<span style=color:#f92672>.</span>create(im))
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;This is </span><span style=color:#e6db74>{</span>member<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Probability it&#39;s </span><span style=color:#e6db74>{</span>member<span style=color:#e6db74>}</span><span style=color:#e6db74>: </span><span style=color:#e6db74>{</span>probs[<span style=color:#ae81ff>0</span>]<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><p>We get correct results for every test images with probability of 0.9 and above.</p><h1 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h1><p>It&rsquo;s incredible how easy it is to train an image classification model in under 30mins and with little data. It would seem that massive amounts of data are required to train something like this, but we&rsquo;ve done it with 60 Images.</p><h1 id=resources-and-links>Resources and Links<a hidden class=anchor aria-hidden=true href=#resources-and-links>#</a></h1><ul><li><a href=https://course.fast.ai/>fast.ai Course</a></li><li><a href=https://github.com/fastai/fastbook/blob/master/01_intro.ipynb>fast.ai book lesson 1</a></li><li><a href=https://forums.fast.ai/t/lesson-1-official-topic/95287>fast.ai forums for lesson 1</a></li><li><a href="https://colab.research.google.com/drive/1WPQS2DZIqTQPAN9x0Q3ocE8d8kk5MTYm?usp=sharing">Colab Notebook for this lesson</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://lordwalnuts.github.io/deeplymind/tags/fast.ai/>fast.ai</a></li><li><a href=https://lordwalnuts.github.io/deeplymind/tags/image-classification/>image classification</a></li><li><a href=https://lordwalnuts.github.io/deeplymind/tags/fast.ai-course/>fast.ai course</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://lordwalnuts.github.io/deeplymind/>DeeplyMind</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>